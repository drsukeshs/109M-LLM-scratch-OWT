{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers datasets accelerate evaluate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-27T05:44:08.564315Z","iopub.execute_input":"2025-09-27T05:44:08.564514Z","iopub.status.idle":"2025-09-27T05:45:25.157362Z","shell.execute_reply.started":"2025-09-27T05:44:08.564488Z","shell.execute_reply":"2025-09-27T05:45:25.156412Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n\ntok  = AutoTokenizer.from_pretrained(\"distilgpt2\")\ntok.pad_token = tok.eos_token\nconfig = AutoConfig.from_pretrained(\"distilgpt2\")\n\nconfig.n_layer = 10              \nconfig.n_positions = 128         \nconfig.n_embd    = 768           \n\nconfig.attn_pdrop = 0.1\nconfig.resid_pdrop = 0.1\n\n\nmodel = AutoModelForCausalLM.from_config(config)\nprint(\"Params:\", f\"{model.num_parameters()/1e6} M\")   # ~109 M","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-27T06:30:34.625164Z","iopub.execute_input":"2025-09-27T06:30:34.625327Z","iopub.status.idle":"2025-09-27T06:31:14.779899Z","shell.execute_reply.started":"2025-09-27T06:30:34.625307Z","shell.execute_reply":"2025-09-27T06:31:14.779077Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ccd31d2051548b1a1c3d8ba5a8ac4d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"436c19c9717e43b88913df5a30989237"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff35c6564f4b4336921b707850233d1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83f1281df3fd4f7d979d105dd259c5ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24a2cc61a6894646a0a3aeec7a41cd44"}},"metadata":{}},{"name":"stderr","text":"2025-09-27 06:30:56.788793: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758954657.135756      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758954657.236744      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Params: 109.575936 M\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset\nds = load_dataset(\"openwebtext\", split=\"train[:50%]\")   # 600 k docs\n\ndef tokenize(ex):\n    return tok(ex[\"text\"],\n               truncation=True,\n               max_length=128,\n               padding=\"max_length\",\n               return_overflowing_tokens=False,\n               return_attention_mask=True)\nds = ds.map(tokenize, batched=True, remove_columns=ds.column_names)\nds = ds.filter(lambda x: len(x[\"input_ids\"]) > 0)      # drop empties","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-27T06:31:41.266195Z","iopub.execute_input":"2025-09-27T06:31:41.266813Z","iopub.status.idle":"2025-09-27T08:41:29.185055Z","shell.execute_reply.started":"2025-09-27T06:31:41.266786Z","shell.execute_reply":"2025-09-27T08:41:29.184268Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac248c3cdf714ce68ece14be47272d32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"openwebtext.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a76c74ba4f9849fbbef873445d4d76ac"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for openwebtext contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/openwebtext.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0/21 [00:00<?, ?files/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd6bb8864d164563834c7d13d819aeee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"subsets/urlsf_subset00.tar:   0%|          | 0.00/633M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"479d385a101243aaaed03ee4bf4ef59f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"subsets/urlsf_subset01.tar:   0%|          | 0.00/629M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6bd486ef1f54a90ba7c4e3928df4a37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"subsets/urlsf_subset02.tar:   0%|          | 0.00/629M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20dbcbb6a21742f8aee27a6b5ffec56f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"subsets/urlsf_subset03.tar:   0%|          | 0.00/628M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b286cfd8fa074273920f4f5b9d5b3591"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"subsets/urlsf_subset04.tar:   0%|          | 0.00/627M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6f4ae4813e14566b34ba351296a503b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"subsets/urlsf_subset05.tar:   0%|          | 0.00/630M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b57a2c7303944754b9ec5b825a8e1d07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"subsets/urlsf_subset06.tar:   0%|          | 0.00/626M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dedf960a42b14e1aa898d83e1d9aca35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"subsets/urlsf_subset07.tar:   0%|          | 0.00/625M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f58c76e169ee406c8153ce87fa2d37c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"subsets/urlsf_subset08.tar:   0%|          | 0.00/625M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f8e96c316aa4150847d939b76f14679"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"subsets/urlsf_subset09.tar:   0%|          | 0.00/626M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7adc71907cb146269df27bae66fe47ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"subsets/urlsf_subset10.tar:   0%|          | 0.00/625M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7be5f019a75a4424ba47ff4fa6a46ee2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"subsets/urlsf_subset11.tar:   0%|          | 0.00/625M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca6e495a67914779b2bb5cecb1d1b005"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"subsets/urlsf_subset12.tar:   0%|          | 0.00/624M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13f1e82259a44d068a0573d07fc66b1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"subsets/urlsf_subset13.tar:   0%|          | 0.00/629M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a10d5c5679714877ad3b3e97ece473ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"subsets/urlsf_subset14.tar:   0%|          | 0.00/627M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41488b6abcec41568e3a4affd665687d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"subsets/urlsf_subset15.tar:   0%|          | 0.00/621M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec5b4efc225441168edcbb8859102b78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"subsets/urlsf_subset16.tar:   0%|          | 0.00/619M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bf16300d6104a3f8874458afc91f27d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"subsets/urlsf_subset17.tar:   0%|          | 0.00/619M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"403f3a071c064624b4d00e567b5f51df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"subsets/urlsf_subset18.tar:   0%|          | 0.00/618M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eeed2d77ab5740dc8e44498ea4c45c54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"subsets/urlsf_subset19.tar:   0%|          | 0.00/619M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a39e9b2f543459298a49e4589610b03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"subsets/urlsf_subset20.tar:   0%|          | 0.00/377M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4554aff04dd5461fa842b54aa1283f66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/8013769 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a7d6517cba349ea91d023387b6dc390"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading dataset shards:   0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83d88db679aa4701b7a86cb6112431c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4006884 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc17cf9eaee3488ca8d5bb438536ef2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/4006884 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9156bce9ae04b69a64c9e15c62f17a7"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"ds.save_to_disk(\"tokenized_openwebtext_50p\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-27T09:13:30.537454Z","iopub.execute_input":"2025-09-27T09:13:30.538100Z","iopub.status.idle":"2025-09-27T09:13:53.683772Z","shell.execute_reply.started":"2025-09-27T09:13:30.538076Z","shell.execute_reply":"2025-09-27T09:13:53.682980Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/6 shards):   0%|          | 0/4006884 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71f12ad67d08474d8cdf9b718c49bf77"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"print(ds)\nprint(f\"Total training samples: {len(ds)}\")\nprint(f\"Total training tokens: {len(ds) * 128:,}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-27T08:41:38.487880Z","iopub.execute_input":"2025-09-27T08:41:38.488154Z","iopub.status.idle":"2025-09-27T08:41:38.492645Z","shell.execute_reply.started":"2025-09-27T08:41:38.488132Z","shell.execute_reply":"2025-09-27T08:41:38.491839Z"}},"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['input_ids', 'attention_mask'],\n    num_rows: 4006884\n})\nTotal training samples: 4006884\nTotal training tokens: 512,881,152\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-27T08:42:43.536162Z","iopub.execute_input":"2025-09-27T08:42:43.536427Z","iopub.status.idle":"2025-09-27T08:42:43.540262Z","shell.execute_reply.started":"2025-09-27T08:42:43.536408Z","shell.execute_reply":"2025-09-27T08:42:43.539562Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\n\nargs = TrainingArguments(\n    output_dir              = \"./pt_platz109M\",\n    per_device_train_batch_size = 8,\n    gradient_accumulation_steps = 8,\n    num_train_epochs        = 3,\n    learning_rate           = 6e-4,\n    lr_scheduler_type       = \"cosine\",\n    warmup_steps            = 500,\n    fp16                    = True,\n    save_strategy           = \"steps\",\n    save_steps              = 500,\n    save_total_limit        = 2,\n    report_to               = \"none\",\n)\n\ndef collate_fn(batch):\n    input_ids = torch.stack([torch.tensor(f[\"input_ids\"]) for f in batch])\n    labels = torch.stack([torch.tensor(f[\"input_ids\"]) for f in batch])\n    return {\"input_ids\": input_ids, \"labels\": labels}\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=ds,\n    data_collator=collate_fn,\n)\ntrainer.train()\ntrainer.save_model(\"pt_platz109M_final\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-27T08:48:57.618590Z","iopub.execute_input":"2025-09-27T08:48:57.619196Z","iopub.status.idle":"2025-09-27T09:09:42.858656Z","shell.execute_reply.started":"2025-09-27T08:48:57.619173Z","shell.execute_reply":"2025-09-27T09:09:42.857414Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='546' max='93912' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  546/93912 20:39 < 59:06:22, 0.44 it/s, Epoch 0.02/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>3.075300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/354813954.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mdata_collator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m )\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pt_platz109M_final\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2238\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2240\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2241\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2242\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2558\u001b[0m                         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2559\u001b[0m                         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_xla_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2560\u001b[0;31m                         \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2561\u001b[0m                     ):\n\u001b[1;32m   2562\u001b[0m                         \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":9},{"cell_type":"code","source":"#restart training from checkpoint","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#reload dataset shards\nfrom datasets import load_from_disk\n\nds = load_from_disk(\"tokenized_openwebtext_50p\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T03:43:56.264687Z","iopub.execute_input":"2025-09-30T03:43:56.265308Z","iopub.status.idle":"2025-09-30T03:43:58.055457Z","shell.execute_reply.started":"2025-09-30T03:43:56.265283Z","shell.execute_reply":"2025-09-30T03:43:58.054718Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"#redefine the same model \nfrom transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n\ntok  = AutoTokenizer.from_pretrained(\"distilgpt2\")\ntok.pad_token = tok.eos_token\nconfig = AutoConfig.from_pretrained(\"distilgpt2\")\n\nconfig.n_layer = 10              \nconfig.n_positions = 128         \nconfig.n_embd    = 768           \n\nconfig.attn_pdrop = 0.1\nconfig.resid_pdrop = 0.1\n\n\nmodel = AutoModelForCausalLM.from_config(config)\nprint(\"Params:\", f\"{model.num_parameters()/1e6} M\")   # ~109 M","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T03:44:05.641640Z","iopub.execute_input":"2025-09-30T03:44:05.642315Z","iopub.status.idle":"2025-09-30T03:44:36.875991Z","shell.execute_reply.started":"2025-09-30T03:44:05.642290Z","shell.execute_reply":"2025-09-30T03:44:36.875246Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dac6e90a722d4bf1a2dc0358ce5b964a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"201a4bd565a94b41bfbc4e7a7d772d0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d01c32c66c3246adb12bd2ed376707ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae671eab8a6448ffaa464ede256aa54f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69653a3f5f3c4928bf14f1cb3b3c89ab"}},"metadata":{}},{"name":"stderr","text":"2025-09-30 03:44:22.841433: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759203863.070000      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1759203863.133091      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Params: 109.575936 M\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"#################################### do not use this\nfrom pathlib import Path\ncheckpoint_dir = sorted(Path(\"./pt_platz109M\").glob(\"checkpoint-*\"))[-1]\ntrainer.train(resume_from_checkpoint=str(checkpoint_dir))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#training args\nfrom transformers import Trainer, TrainingArguments\n\nargs = TrainingArguments(\n    output_dir              = \"./pt_platz109M\",\n    per_device_train_batch_size = 8,\n    gradient_accumulation_steps = 8,\n    num_train_epochs        = 3,\n    learning_rate           = 6e-4,\n    lr_scheduler_type       = \"cosine\",\n    warmup_steps            = 500,\n    fp16                    = True,\n    save_strategy           = \"steps\",\n    save_steps              = 500,\n    save_total_limit        = 2,\n    report_to               = \"none\",\n)\n\ndef collate_fn(batch):\n    input_ids = torch.stack([torch.tensor(f[\"input_ids\"]) for f in batch])\n    labels = torch.stack([torch.tensor(f[\"input_ids\"]) for f in batch])\n    return {\"input_ids\": input_ids, \"labels\": labels}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T03:44:42.779322Z","iopub.execute_input":"2025-09-30T03:44:42.780492Z","iopub.status.idle":"2025-09-30T03:44:44.949085Z","shell.execute_reply.started":"2025-09-30T03:44:42.780456Z","shell.execute_reply":"2025-09-30T03:44:44.948138Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"#training loop\nimport torch\nmodel.gradient_checkpointing_enable()\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=ds,\n    data_collator=collate_fn,\n)\n\n\nfrom pathlib import Path\ncheckpoints = sorted(Path(args.output_dir).glob(\"checkpoint-*\"))\nif checkpoints:\n    last_checkpoint = str(checkpoints[-1])\n    trainer.train(resume_from_checkpoint=last_checkpoint)\nelse:\n    trainer.train()\n\ntrainer.save_model(\"pt_platz109M_final\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T03:44:51.410611Z","iopub.execute_input":"2025-09-30T03:44:51.410897Z","iopub.status.idle":"2025-09-30T08:56:07.112995Z","shell.execute_reply.started":"2025-09-30T03:44:51.410875Z","shell.execute_reply":"2025-09-30T08:56:07.111616Z"}},"outputs":[{"name":"stderr","text":"There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\nWarning: The following arguments do not match the ones in the `trainer_state.json` within the checkpoint directory: \n\tper_device_train_batch_size: 8 (from args) != 16 (from trainer_state.json)\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='33121' max='93912' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [33121/93912 5:11:09 < 41:22:41, 0.41 it/s, Epoch 1.06/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>26000</td>\n      <td>3.543800</td>\n    </tr>\n    <tr>\n      <td>26500</td>\n      <td>3.546100</td>\n    </tr>\n    <tr>\n      <td>27000</td>\n      <td>3.535600</td>\n    </tr>\n    <tr>\n      <td>27500</td>\n      <td>3.532100</td>\n    </tr>\n    <tr>\n      <td>28000</td>\n      <td>3.526800</td>\n    </tr>\n    <tr>\n      <td>28500</td>\n      <td>3.522500</td>\n    </tr>\n    <tr>\n      <td>29000</td>\n      <td>3.516700</td>\n    </tr>\n    <tr>\n      <td>29500</td>\n      <td>3.515200</td>\n    </tr>\n    <tr>\n      <td>30000</td>\n      <td>3.510600</td>\n    </tr>\n    <tr>\n      <td>30500</td>\n      <td>3.508700</td>\n    </tr>\n    <tr>\n      <td>31000</td>\n      <td>3.504900</td>\n    </tr>\n    <tr>\n      <td>31500</td>\n      <td>3.486600</td>\n    </tr>\n    <tr>\n      <td>32000</td>\n      <td>3.457400</td>\n    </tr>\n    <tr>\n      <td>32500</td>\n      <td>3.452400</td>\n    </tr>\n    <tr>\n      <td>33000</td>\n      <td>3.452700</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3206890331.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcheckpoints\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mlast_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2238\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2240\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2241\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2242\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2553\u001b[0m                     )\n\u001b[1;32m   2554\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2555\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2557\u001b[0m                     if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3789\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scale_wrt_gas\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3791\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3793\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2547\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2548\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2549\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2550\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_lomo_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2551\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlomo_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":4}]}